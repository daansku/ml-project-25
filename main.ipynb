{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93084734",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk \n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51d10878",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the dataset and clean it\n",
        "\n",
        "df = pd.read_csv(\"train.tsv\", sep=\"\\t\")\n",
        "\n",
        "df.drop(columns=[\"2635.json\", \"dwayne-bohac\", \"State representative\", \"Texas\", \"republican\", \"a mailer\"], inplace=True)\n",
        "df.rename(columns={\"\": \"Index\",\n",
        "                    \"false\": \"correctness\",\n",
        "                    \"Says the Annies List political group supports third-trimester abortions on demand.\": \"Text\",\n",
        "                    \"abortion\": \"Theme\",\n",
        "                    \"0\": \"barely true counts\",\n",
        "                    \"1\": \"false counts\",\n",
        "                    \"0.1\": \"half true counts\",\n",
        "                    \"0.2\": \"mostly true counts\",\n",
        "                    \"0.3\": \"pants on fire counts\",}, inplace=True)\n",
        "\n",
        "# download necessary NLTK resources (only once)\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"averaged_perceptron_tagger_eng\")\n",
        "\n",
        "# set of stop words to filter out\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# initialize lemmatizer\n",
        "lemmatizer = nltk.WordNetLemmatizer()\n",
        "\n",
        "# clean text from stop words and lemmatize\n",
        "df[\"Cleaned text\"] = df[\"Text\"].apply(\n",
        "    lambda x: \" \".join(\n",
        "        [word for word in word_tokenize(str(x).lower()) if word.isalnum() and word not in stop_words]\n",
        "    )\n",
        ")\n",
        "\n",
        "df[\"Cleaned text\"] = df[\"Cleaned text\"].apply(\n",
        "    lambda x: \" \".join(\n",
        "        [lemmatizer.lemmatize(w) for w in word_tokenize(str(x).lower()) if w.isalnum()]\n",
        "    )\n",
        ")\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e46987fc",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get labels from the 'corectness' column\n",
        "label_order = ['pants-fire', 'false', 'barely-true', 'half-true', 'mostly-true', 'true']\n",
        "label_map = {label: idx for idx, label in enumerate(label_order)}\n",
        "\n",
        "# Encode the labels\n",
        "df['label'] = df['correctness'].map(label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "650f94b7",
      "metadata": {},
      "outputs": [],
      "source": [
        "corpus = df[\"Cleaned text\"]\n",
        "corpus\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a8be63b",
      "metadata": {},
      "outputs": [],
      "source": [
        "v = TfidfVectorizer()\n",
        "transformed_output = v.fit_transform(corpus)\n",
        "print(v.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6eae71bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_names = v.get_feature_names_out()\n",
        "\n",
        "for word in feature_names[1000:1100]:\n",
        "    indx = v.vocabulary_.get(word)\n",
        "    print(f\"{word}: {v.idf_[indx]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba322f9c",
      "metadata": {},
      "outputs": [],
      "source": [
        "tfidf_df = pd.DataFrame(transformed_output.toarray(), columns=feature_names)\n",
        "# tfidf_df.iloc[0].sort_values(ascending=False).head(10)\n",
        "tfidf_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "feba9569",
      "metadata": {},
      "outputs": [],
      "source": [
        "X = tfidf_df.values\n",
        "y = df['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65be0863",
      "metadata": {},
      "outputs": [],
      "source": [
        "clf = LogisticRegression()\n",
        "clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9afad41",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
