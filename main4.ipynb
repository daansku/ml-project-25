{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6bf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import os\n",
    "import imutils\n",
    "\n",
    "# Preprocess images, code from github https://github.com/masoudnick/Brain-Tumor-MRI-Classification/blob/main/Preprocessing.py\n",
    "\n",
    "def crop_img(img):\n",
    "\t\"\"\"\n",
    "\tFinds the extreme points on the image and crops the rectangular out of them\n",
    "\t\"\"\"\n",
    "\tgray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\tgray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "\n",
    "\t# threshold the image, then perform a series of erosions +\n",
    "\t# dilations to remove any small regions of noise\n",
    "\tthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\n",
    "\tthresh = cv2.erode(thresh, None, iterations=2)\n",
    "\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "\t# find contours in thresholded image, then grab the largest one\n",
    "\tcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\tcnts = imutils.grab_contours(cnts)\n",
    "\tc = max(cnts, key=cv2.contourArea)\n",
    "\n",
    "\t# find the extreme points\n",
    "\textLeft = tuple(c[c[:, :, 0].argmin()][0])\n",
    "\textRight = tuple(c[c[:, :, 0].argmax()][0])\n",
    "\textTop = tuple(c[c[:, :, 1].argmin()][0])\n",
    "\textBot = tuple(c[c[:, :, 1].argmax()][0])\n",
    "\tADD_PIXELS = 0\n",
    "\tnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()\n",
    "\t\n",
    "\treturn new_img\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c25af71",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m image_dir:\n\u001b[32m     12\u001b[39m     image = cv2.imread(os.path.join(path,img))\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     new_img = \u001b[43mcrop_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     new_img = cv2.resize(new_img,(IMG_SIZE,IMG_SIZE))\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(save_path):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mcrop_img\u001b[39m\u001b[34m(img)\u001b[39m\n\u001b[32m     18\u001b[39m thresh = cv2.threshold(gray, \u001b[32m45\u001b[39m, \u001b[32m255\u001b[39m, cv2.THRESH_BINARY)[\u001b[32m1\u001b[39m]\n\u001b[32m     19\u001b[39m thresh = cv2.erode(thresh, \u001b[38;5;28;01mNone\u001b[39;00m, iterations=\u001b[32m2\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m thresh = \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdilate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthresh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# find contours in thresholded image, then grab the largest one\u001b[39;00m\n\u001b[32m     23\u001b[39m cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "training = \"Training\"\n",
    "testing = \"Testing\"\n",
    "training_dir = os.listdir(training)\n",
    "testing_dir = os.listdir(testing)\n",
    "IMG_SIZE = 256\n",
    "\n",
    "for dir in training_dir:\n",
    "    save_path = 'cleaned/Training/'+ dir\n",
    "    path = os.path.join(training,dir)\n",
    "    image_dir = os.listdir(path)\n",
    "    for img in image_dir:\n",
    "        image = cv2.imread(os.path.join(path,img))\n",
    "        new_img = crop_img(image)\n",
    "        new_img = cv2.resize(new_img,(IMG_SIZE,IMG_SIZE))\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        cv2.imwrite(save_path+'/'+img, new_img)\n",
    "\n",
    "for dir in testing_dir:\n",
    "    save_path = 'cleaned/Testing/'+ dir\n",
    "    path = os.path.join(testing,dir)\n",
    "    image_dir = os.listdir(path)\n",
    "    for img in image_dir:\n",
    "        image = cv2.imread(os.path.join(path,img))\n",
    "        new_img = crop_img(image)\n",
    "        new_img = cv2.resize(new_img,(IMG_SIZE,IMG_SIZE))\n",
    "        if not os.path.exists(save_path):\n",
    "            os.makedirs(save_path)\n",
    "        cv2.imwrite(save_path+'/'+img, new_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e83cce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8924485125858124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def super_simple_load(data_dir, img_size=(64, 64)):\n",
    "    X, y = [], []\n",
    "    \n",
    "    for folder in os.listdir(data_dir):\n",
    "        folder_path = os.path.join(data_dir, folder)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            continue\n",
    "            \n",
    "        label = len(set(y))\n",
    "        \n",
    "        for img_file in os.listdir(folder_path):\n",
    "            if img_file.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "                img_path = os.path.join(folder_path, img_file)\n",
    "                img = cv2.imread(img_path, 0)  # Grayscale\n",
    "                img = cv2.resize(img, img_size).flatten() / 255.0\n",
    "                \n",
    "                X.append(img)\n",
    "                y.append(label)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# load the data and split them into train and test\n",
    "X_train, y_train = super_simple_load(\"training/\")\n",
    "X_test, y_test = super_simple_load(\"testing/\")\n",
    "\n",
    "# train that shit\n",
    "model = LogisticRegression(max_iter=10000).fit(X_train, y_train)\n",
    "print(f\"Accuracy: {model.score(X_test, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
